Er gebeurt veel onderzoek over gigantische taalmodellen (Large Language Models, Foundation Models)  in Amsterdam. Hier is selectie van onderzoek en onderzoekers.

## Arabella Sinclair, Jaap Jumelet, Willem Zuidema, Raquel Fernández (2022)
Onderzoek naar hoeveel kennis van grammatica-regels taalmodellen hebben geleerd.

### Blog-post 
[ILLC Blog](https://resources.illc.uva.nl/illc-blog/probing-by-priming-what-do-large-language-models-know-about-grammar/)

### Wetenschappelijke publicatie: 
Arabella Sinclair, Jaap Jumelet, Willem Zuidema, Raquel Fernández; Structural Persistence in Language Models: Priming as a Window into Abstract Language Representations. Transactions of the Association for Computational Linguistics 2022; 10 1031–1050. [doi](https://doi.org/10.1162/tacl_a_00504) [arxiv](https://arxiv.org/abs/2109.14989)


## Oskar van der Wal, Dominik Bachmann, Alina Leidinger, Leendert van Maanen, Willem Zuidema, Katrin Schulz (2022)
Onderzoek naar ongewenste biases in taalmodellen en hoe we die kunnen meten en voorkomen.

### Wetenschappelijke publicatie: 
Oskar van der Wal, Dominik Bachmann, Alina Leidinger, Leendert van Maanen, Willem Zuidema, Katrin Schulz (2022), Undesirable biases in NLP: Averting a crisis of measurement. [arxiv](https://arxiv.org/abs/2211.13709)


## Oskar van der Wal, Jaap Jumelet, Katrin Schulz, Willem Zuidema 
Onderzoek naar het ontstaan van ongewenste biases in grote taalmodellen.

### Wetenschappelijke publicatie: 
Oskar van der Wal, Jaap Jumelet, Katrin Schulz, Willem Zuidema (2022), The Birth of Bias: A case study on the evolution of gender bias in an English language model. [arxiv](https://arxiv.org/abs/2207.10245)


## Oskar van der Wal en 390 andere auteurs (2022)
Het veeltalige, open-source taalmodel BLOOM van het BigScience consortium.

### Wetenschappelijke publicatie: 
BigScience Workshop et al., BLOOM: A 176B-Parameter Open-Access Multilingual Language Model, 2022.
[arxiv](https://arxiv.org/abs/2211.05100)


## Rochelle Choeni, Ekaterina Shutova en Robert van Rooij (2021) 
Onderzoek naar (ongewenste) stereotypen die opduiken in taalmodellen en zoekmachines.

### Persbericht
[UvA persberichten](https://www.uva.nl/content/nieuws/persberichten/2021/11/welke-stereotypen-zitten-ingebakken-in-ai-taalmodellen.html?origin=8geT2goFTZSNjbHsS7pkaQ)

### Wetenschappelijke publicatie: 
Stepmothers are mean and academics are pretentious: What do pretrained language models learn about you? Gepresenteerd op de 2021 Conference on Empirical Methods in Natural Language Processing (EMNLP2021), 7 november 2021. [Weblink naar de wetenschappelijke publicatie](https://aclanthology.org/2021.emnlp-main.111/).


